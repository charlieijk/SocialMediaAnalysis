{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202ac01-0c11-4de6-84f0-bf4da193fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, scipy, sklearn\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0498d7a-c819-40cc-8d68-b70e0b861b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load simple_flask_app.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simplified Flask app for Social Media Sentiment Analysis Platform\n",
    "This version works with basic dependencies and demonstrates core functionality.\n",
    "\"\"\"\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template_string\n",
    "from flask_cors import CORS\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TF_AVAILABLE = Truej\n",
    "except ModuleNotFoundError:\n",
    "    tf = None\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Simple Text Preprocessor (same as in simple_demo.py)\n",
    "class SimpleTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            nltk.data.find('tokenizers/punkt_tab')\n",
    "            nltk.data.find('corpora/stopwords')\n",
    "            nltk.data.find('corpora/wordnet')\n",
    "        except LookupError:\n",
    "            nltk.download('punkt_tab')\n",
    "            nltk.download('stopwords')\n",
    "            nltk.download('wordnet')\n",
    "\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        lemmatized_tokens = [\n",
    "            self.lemmatizer.lemmatize(token)\n",
    "            for token in tokens\n",
    "            if token not in self.stop_words and len(token) > 2\n",
    "        ]\n",
    "        return lemmatized_tokens\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        tokens = self.tokenize_and_lemmatize(cleaned_text)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "# Simple Sentiment Analyzer\n",
    "class SimpleSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "        self.preprocessor = SimpleTextPreprocessor()\n",
    "        self.is_trained = False\n",
    "        self.sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "        self.neural_enabled = TF_AVAILABLE\n",
    "\n",
    "        # Initialize with sample data for demo\n",
    "        self._train_with_sample_data()\n",
    "\n",
    "    def _build_neural_network(self, input_dim, num_classes=3):\n",
    "        \"\"\"Create a lightweight dense neural network for demo purposes.\"\"\"\n",
    "        if not self.neural_enabled or tf is None:\n",
    "            raise RuntimeError(\"TensorFlow is required for the neural network demo.\")\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.4),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def _train_neural_network(self, X, y):\n",
    "        \"\"\"Train the neural network on dense TF-IDF features.\"\"\"\n",
    "        if not self.neural_enabled or tf is None:\n",
    "            return None\n",
    "        X_dense = X.toarray().astype('float32')\n",
    "        y_array = np.array(y, dtype=np.int32)\n",
    "        model = self._build_neural_network(X_dense.shape[1], len(self.sentiment_labels))\n",
    "        # Small dataset -> keep epochs low to avoid overfitting while still demonstrating NN usage\n",
    "        model.fit(X_dense, y_array, epochs=25, batch_size=16, verbose=0)\n",
    "        return model\n",
    "\n",
    "    def _predict_neural_network(self, model, X):\n",
    "        \"\"\"Predict sentiment probabilities with the neural network.\"\"\"\n",
    "        X_dense = X.toarray().astype('float32')\n",
    "        probabilities = model.predict(X_dense, verbose=0)[0]\n",
    "        prediction = int(np.argmax(probabilities))\n",
    "        return prediction, probabilities\n",
    "\n",
    "    def _train_with_sample_data(self):\n",
    "        \"\"\"Train models with sample data for demonstration\"\"\"\n",
    "        sample_tweets = [\n",
    "            \"I absolutely love this new product! It's amazing!\",\n",
    "            \"This is the worst service I've ever experienced. Terrible!\",\n",
    "            \"The weather is okay today, nothing special.\",\n",
    "            \"Best purchase I've made this year! Highly recommend!\",\n",
    "            \"Not impressed with the quality. Could be better.\",\n",
    "            \"Feeling great today! Life is beautiful!\",\n",
    "            \"The movie was boring and too long. Waste of time.\",\n",
    "            \"Pretty good overall experience. Satisfied with the results.\",\n",
    "            \"Absolutely hate this new update. Ruined everything!\",\n",
    "            \"Amazing customer service! They went above and beyond!\",\n",
    "            \"This is confusing and hard to use.\",\n",
    "            \"Love the new features! Great job!\",\n",
    "            \"It's fine, works as expected.\",\n",
    "            \"Incredible performance! Exceeded expectations!\",\n",
    "            \"Terrible experience. Very disappointed.\",\n",
    "            \"Outstanding quality and service!\",\n",
    "            \"Could be much better, disappointed.\",\n",
    "            \"Average product, nothing special.\",\n",
    "            \"Fantastic experience, will definitely return!\",\n",
    "            \"Poor quality, would not recommend.\"\n",
    "        ]\n",
    "\n",
    "        expected_labels = [2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 1, 2, 0]\n",
    "\n",
    "        # Preprocess and vectorize\n",
    "        preprocessed_texts = [self.preprocessor.preprocess(text) for text in sample_tweets]\n",
    "        X = self.vectorizer.fit_transform(preprocessed_texts)\n",
    "        y = np.array(expected_labels)\n",
    "\n",
    "        # Train models\n",
    "        self.models['naive_bayes'] = MultinomialNB().fit(X, y)\n",
    "        self.models['svm'] = SVC(probability=True, random_state=42).fit(X, y)\n",
    "        self.models['logistic_regression'] = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "        self.models['random_forest'] = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=None,\n",
    "            random_state=42\n",
    "        ).fit(X, y)\n",
    "        if self.neural_enabled:\n",
    "            self.models['neural_network'] = self._train_neural_network(X, y)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è TensorFlow not installed; skipping neural network demo. Run 'pip install tensorflow' to enable it.\")\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "    def analyze_text(self, text, model_name='svm'):\n",
    "        \"\"\"Analyze sentiment of a single text\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return {'error': 'Models are still initializing. Please try again in a moment.'}\n",
    "\n",
    "        if model_name == 'neural_network' and not self.neural_enabled:\n",
    "            return {'error': \"Neural network demo disabled because TensorFlow isn't installed. Run 'pip install tensorflow' to enable it.\"}\n",
    "\n",
    "        if model_name not in self.models:\n",
    "            return {'error': f\"Model '{model_name}' not available\"}\n",
    "\n",
    "        # Preprocess text\n",
    "        preprocessed_text = self.preprocessor.preprocess(text)\n",
    "\n",
    "        # Transform to features\n",
    "        X = self.vectorizer.transform([preprocessed_text])\n",
    "\n",
    "        # Make prediction\n",
    "        model = self.models[model_name]\n",
    "        if model_name == 'neural_network':\n",
    "            prediction, probabilities = self._predict_neural_network(model, X)\n",
    "        else:\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                probabilities = model.predict_proba(X)[0]\n",
    "                prediction = int(np.argmax(probabilities))\n",
    "            else:\n",
    "                prediction = int(model.predict(X)[0])\n",
    "                probabilities = None\n",
    "\n",
    "        confidence = float(np.max(probabilities) * 100) if probabilities is not None else None\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'sentiment': self.sentiment_labels[prediction],\n",
    "            'sentiment_score': int(prediction),\n",
    "            'confidence': round(confidence, 1) if confidence is not None else None,\n",
    "            'probabilities': self._format_probabilities(probabilities),\n",
    "            'model_used': model_name\n",
    "        }\n",
    "\n",
    "    def compare_models(self, text):\n",
    "        \"\"\"Compare results across all models\"\"\"\n",
    "        results = {}\n",
    "        for model_name in self.models.keys():\n",
    "            results[model_name] = self.analyze_text(text, model_name)\n",
    "        return results\n",
    "\n",
    "    def _format_probabilities(self, probabilities):\n",
    "        \"\"\"Convert probability vectors into a friendly dict for JSON responses.\"\"\"\n",
    "        if probabilities is None:\n",
    "            return None\n",
    "        probs = [round(float(p) * 100, 1) for p in probabilities]\n",
    "        while len(probs) < 3:\n",
    "            probs.append(0.0)\n",
    "        return {\n",
    "            'negative': probs[0],\n",
    "            'neutral': probs[1],\n",
    "            'positive': probs[2]\n",
    "        }\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = SimpleSentimentAnalyzer()\n",
    "\n",
    "# Simple HTML template for the web interface\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Social Media Sentiment Analysis</title>\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }\n",
    "        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }\n",
    "        h1 { color: #333; text-align: center; margin-bottom: 30px; }\n",
    "        .input-section { margin-bottom: 30px; }\n",
    "        textarea { width: 100%; height: 100px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; font-size: 14px; }\n",
    "        button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; font-size: 16px; margin: 10px 5px 0 0; }\n",
    "        button:hover { background: #0056b3; }\n",
    "        .results { margin-top: 20px; }\n",
    "        .result-box { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007bff; }\n",
    "        .positive { border-left-color: #28a745; }\n",
    "        .negative { border-left-color: #dc3545; }\n",
    "        .neutral { border-left-color: #ffc107; }\n",
    "        .confidence { font-weight: bold; }\n",
    "        .probabilities { font-size: 12px; color: #666; margin-top: 5px; }\n",
    "        .demo-buttons { text-align: center; margin: 20px 0; }\n",
    "        .demo-text { background: #e9ecef; padding: 10px; border-radius: 5px; margin: 5px 0; cursor: pointer; }\n",
    "        .demo-text:hover { background: #dee2e6; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>üé≠ Social Media Sentiment Analysis</h1>\n",
    "\n",
    "        <div class=\"demo-buttons\">\n",
    "            <h3>Try some examples:</h3>\n",
    "            <div class=\"demo-text\" onclick=\"setDemoText('I absolutely love this new product! Amazing quality and service!')\">\n",
    "                üòä \"I absolutely love this new product! Amazing quality and service!\"\n",
    "            </div>\n",
    "            <div class=\"demo-text\" onclick=\"setDemoText('This is terrible service. Very disappointed and frustrated.')\">\n",
    "                üòû \"This is terrible service. Very disappointed and frustrated.\"\n",
    "            </div>\n",
    "            <div class=\"demo-text\" onclick=\"setDemoText('The product is okay, nothing special but does what it says.')\">\n",
    "                üòê \"The product is okay, nothing special but does what it says.\"\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"input-section\">\n",
    "            <textarea id=\"textInput\" placeholder=\"Enter text to analyze sentiment... (e.g., tweets, reviews, comments)\"></textarea>\n",
    "            <br>\n",
    "            <button onclick=\"analyzeSingle()\">Analyze with SVM</button>\n",
    "            <button onclick=\"compareModels()\">Compare All Models</button>\n",
    "            <button onclick=\"clearResults()\">Clear Results</button>\n",
    "        </div>\n",
    "\n",
    "        <div id=\"results\" class=\"results\"></div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function setDemoText(text) {\n",
    "            document.getElementById('textInput').value = text;\n",
    "        }\n",
    "\n",
    "        function analyzeSingle() {\n",
    "            const text = document.getElementById('textInput').value;\n",
    "            if (!text.trim()) {\n",
    "                alert('Please enter some text to analyze');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            fetch('/api/analyze', {\n",
    "                method: 'POST',\n",
    "                headers: {'Content-Type': 'application/json'},\n",
    "                body: JSON.stringify({text: text, model: 'svm'})\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => displaySingleResult(data))\n",
    "            .catch(error => console.error('Error:', error));\n",
    "        }\n",
    "\n",
    "        function compareModels() {\n",
    "            const text = document.getElementById('textInput').value;\n",
    "            if (!text.trim()) {\n",
    "                alert('Please enter some text to analyze');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            fetch('/api/compare', {\n",
    "                method: 'POST',\n",
    "                headers: {'Content-Type': 'application/json'},\n",
    "                body: JSON.stringify({text: text})\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => displayComparisonResults(data))\n",
    "            .catch(error => console.error('Error:', error));\n",
    "        }\n",
    "\n",
    "        function displaySingleResult(data) {\n",
    "            const resultsDiv = document.getElementById('results');\n",
    "            const sentimentClass = data.sentiment.toLowerCase();\n",
    "\n",
    "            resultsDiv.innerHTML = `\n",
    "                <div class=\"result-box ${sentimentClass}\">\n",
    "                    <h3>Analysis Result</h3>\n",
    "                    <p><strong>Text:</strong> \"${data.text}\"</p>\n",
    "                    <p><strong>Sentiment:</strong> ${data.sentiment} <span class=\"confidence\">(${data.confidence}% confidence)</span></p>\n",
    "                    <p><strong>Model:</strong> ${data.model_used.replace('_', ' ').toUpperCase()}</p>\n",
    "                    <div class=\"probabilities\">\n",
    "                        Probabilities: Negative ${data.probabilities.negative}% |\n",
    "                        Neutral ${data.probabilities.neutral}% |\n",
    "                        Positive ${data.probabilities.positive}%\n",
    "                    </div>\n",
    "                </div>\n",
    "            `;\n",
    "        }\n",
    "\n",
    "        function displayComparisonResults(data) {\n",
    "            const resultsDiv = document.getElementById('results');\n",
    "            let html = '<h3>Model Comparison Results</h3>';\n",
    "\n",
    "            for (const [modelName, result] of Object.entries(data)) {\n",
    "                const sentimentClass = result.sentiment.toLowerCase();\n",
    "                html += `\n",
    "                    <div class=\"result-box ${sentimentClass}\">\n",
    "                        <h4>${modelName.replace('_', ' ').toUpperCase()}</h4>\n",
    "                        <p><strong>Sentiment:</strong> ${result.sentiment} <span class=\"confidence\">(${result.confidence}% confidence)</span></p>\n",
    "                        <div class=\"probabilities\">\n",
    "                            Probabilities: Negative ${result.probabilities.negative}% |\n",
    "                            Neutral ${result.probabilities.neutral}% |\n",
    "                            Positive ${result.probabilities.positive}%\n",
    "                        </div>\n",
    "                    </div>\n",
    "                `;\n",
    "            }\n",
    "\n",
    "            resultsDiv.innerHTML = html;\n",
    "        }\n",
    "\n",
    "        function clearResults() {\n",
    "            document.getElementById('results').innerHTML = '';\n",
    "            document.getElementById('textInput').value = '';\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Main page\"\"\"\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/api/health')\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'models_available': list(sentiment_analyzer.models.keys()),\n",
    "        'models_trained': sentiment_analyzer.is_trained\n",
    "    })\n",
    "\n",
    "@app.route('/api/analyze', methods=['POST'])\n",
    "def analyze_sentiment():\n",
    "    \"\"\"Analyze sentiment of text\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        text = data.get('text', '')\n",
    "        model = data.get('model', 'svm')\n",
    "\n",
    "        if not text.strip():\n",
    "            return jsonify({'error': 'Text is required'}), 400\n",
    "\n",
    "        result = sentiment_analyzer.analyze_text(text, model)\n",
    "        return jsonify(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/compare', methods=['POST'])\n",
    "def compare_models():\n",
    "    \"\"\"Compare sentiment analysis across all models\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        text = data.get('text', '')\n",
    "\n",
    "        if not text.strip():\n",
    "            return jsonify({'error': 'Text is required'}), 400\n",
    "\n",
    "        results = sentiment_analyzer.compare_models(text)\n",
    "        return jsonify(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/models')\n",
    "def get_models():\n",
    "    \"\"\"Get available models\"\"\"\n",
    "    return jsonify({\n",
    "        'models': list(sentiment_analyzer.models.keys()),\n",
    "        'default_model': 'svm',\n",
    "        'sentiment_labels': sentiment_analyzer.sentiment_labels\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"üöÄ Starting Social Media Sentiment Analysis Web App...\")\n",
    "    print(\"üìä Models available:\", list(sentiment_analyzer.models.keys()))\n",
    "    print(\"üåê Web interface will be available at: http://localhost:5001\")\n",
    "    print(\"üîç API endpoints:\")\n",
    "    print(\"  - GET  /api/health\")\n",
    "    print(\"  - POST /api/analyze\")\n",
    "    print(\"  - POST /api/compare\")\n",
    "    print(\"  - GET  /api/models\")\n",
    "    print(\"\\n‚ú® Ready to analyze sentiment! Open http://localhost:5001 in your browser\")\n",
    "\n",
    "    app.run(debug=True, host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb51875-01d7-4e19-a523-a9aee15ddfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "py = sys.executable\n",
    "\n",
    "# Keep build tools fresh\n",
    "!{py} -m pip install -U pip setuptools wheel\n",
    "\n",
    "# Choose the right TF for your Mac\n",
    "if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "    # Apple Silicon: use macOS build + Metal acceleration\n",
    "    !{py} -m pip install -U \"tensorflow-macos>=2.16,<3\" tensorflow-metal\n",
    "else:\n",
    "    # Intel Mac / other OS\n",
    "    !{py} -m pip install -U \"tensorflow>=2.16,<3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785d3df-6ef4-4f69-a428-5baeaf8e473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Keep your host/port as you like; the key is turning these OFF in Jupyter.\n",
    "    app.run(host=\"127.0.0.1\", port=5001, debug=False, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
